{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.data_utils import load_simulation_data\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_logis(X,y,model):\n",
    "    \"\"\"find gradients of cost function w.r.t. the coefficients in logistic regression\"\"\"\n",
    "    prob = model.predict_proba(X)\n",
    "    prob1 = prob[:,1]\n",
    "    X1 = np.hstack([np.ones((X.shape[0],1)), X])\n",
    "    grad = np.matmul(np.diag(prob1-y),X1)\n",
    "    return grad\n",
    "\n",
    "def grad_logis_prob(X,model):\n",
    "    \"\"\"find gradients of predicted probability w.r.t. the coefficients in logistic regression\"\"\"\n",
    "    prob = model.predict_proba(X)\n",
    "    prob01 = prob[:,0]*prob[:,1]\n",
    "    X1 = np.hstack([np.ones((X.shape[0],1)), X])\n",
    "    grad = -np.matmul(np.diag(prob01),X1)\n",
    "    return grad\n",
    "\n",
    "def grad_logis_ent(X, model):\n",
    "    \"\"\"find gradients of entropy w.r.t the coefficients in logistic regression\"\"\"\n",
    "    logprob = model.predict_log_proba(X)\n",
    "    logprob1m0 = -(logprob[:,1]-logprob[:,0])\n",
    "    pgrad = grad_logis_prob(X,model)\n",
    "    grad = np.matmul(np.diag(logprob1m0), pgrad)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L0 = 200\n",
    "B = 20\n",
    "n_iter = 50\n",
    "rep = 10\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tr = np.zeros((rep,n_iter))\n",
    "acc_tr0 = np.zeros((rep,n_iter))\n",
    "acc_tr1 = np.zeros((rep,n_iter))\n",
    "acc_L = np.zeros((rep,n_iter))\n",
    "acc_L0 = np.zeros((rep,n_iter))\n",
    "acc_L1 = np.zeros((rep,n_iter))\n",
    "acc_U = np.zeros((rep,n_iter))\n",
    "acc_U0 = np.zeros((rep,n_iter))\n",
    "acc_U1 = np.zeros((rep,n_iter))\n",
    "acc_te = np.zeros((rep,n_iter))\n",
    "acc_te0 = np.zeros((rep,n_iter))\n",
    "acc_te1 = np.zeros((rep,n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srp/.pyenv/versions/miniconda3-4.7.12/envs/pytorch15/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "for state in range(rep):\n",
    "    print(state)\n",
    "    Xtr,Xte,ytr,yte,ztr,zte = load_simulation_data(simulation_params = {'p':100,'q':40, 'r':10, 'b':0, 't':0}, \n",
    "                                               n1=2000, n2=1000, svm=False, random_state=state, intercept=False, \n",
    "                                               train_frac = 0.7)\n",
    "    # data preprocessing\n",
    "    yytr = ytr.ravel()\n",
    "    yyte = yte.ravel()\n",
    "    zztr = ztr.ravel()\n",
    "    zzte = zte.ravel()\n",
    "    Xtr0 = Xtr[zztr==0]\n",
    "    Xtr1 = Xtr[zztr==1]\n",
    "    Xte0 = Xte[zzte==0]\n",
    "    Xte1 = Xte[zzte==1]\n",
    "    yytr0 = yytr[zztr==0]\n",
    "    yytr1 = yytr[zztr==1]\n",
    "    yyte0 = yyte[zzte==0]\n",
    "    yyte1 = yyte[zzte==1]\n",
    "    \n",
    "    # initialization\n",
    "    N = zztr.shape[0]\n",
    "    perm = np.random.permutation(N)\n",
    "    XL = Xtr[perm[0:L0],:]\n",
    "    XU = Xtr[perm[L0:],:]\n",
    "    yL = yytr[perm[0:L0]]\n",
    "    yU = yytr[perm[L0:]]\n",
    "    zL = zztr[perm[0:L0]]\n",
    "    zU = zztr[perm[L0:]]\n",
    "    XL0 = XL[zL==0]\n",
    "    XL1 = XL[zL==1]\n",
    "    yL0 = yL[zL==0]\n",
    "    yL1 = yL[zL==1]\n",
    "    XU0 = XU[zU==0]\n",
    "    XU1 = XU[zU==1]\n",
    "    yU0 = yU[zU==0]\n",
    "    yU1 = yU[zU==1]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # model fitting and prediction\n",
    "        clf=LR(random_state=state).fit(XL, yL)\n",
    "        acc_tr[state, i] = clf.score(Xtr, yytr)\n",
    "        acc_tr0[state, i] = clf.score(Xtr0, yytr0)\n",
    "        acc_tr1[state, i] = clf.score(Xtr1, yytr1)\n",
    "        acc_L[state, i] = clf.score(XL, yL)\n",
    "        acc_L0[state, i] = clf.score(XL0, yL0)\n",
    "        acc_L1[state, i] = clf.score(XL1, yL1)\n",
    "        acc_U[state, i] = clf.score(XU, yU)\n",
    "        acc_U0[state, i] = clf.score(XU0, yU0)\n",
    "        acc_U1[state, i] = clf.score(XU1, yU1)\n",
    "        acc_te[state, i] = clf.score(Xte, yyte)\n",
    "        acc_te0[state, i] = clf.score(Xte0, yyte0)\n",
    "        acc_te1[state, i] = clf.score(Xte1, yyte1)\n",
    "        \n",
    "        # modify next labeled and ulabeled sets\n",
    "        \n",
    "        # worst group selection\n",
    "        if acc_L0[state, i]<acc_L1[state, i]:\n",
    "            wg = 0\n",
    "            Xw = XL0\n",
    "            yw = yL0\n",
    "        else:\n",
    "            wg = 1\n",
    "            Xw = XL1\n",
    "            yw = yL1\n",
    "        \n",
    "        # find gradients\n",
    "        \n",
    "        grad_w = np.mean(grad_logis(Xw, yw, clf), axis=0)\n",
    "        # print(grad_w.shape)\n",
    "        grad1 = grad_logis_prob(XU,clf)\n",
    "        grad0 = -grad1\n",
    "        # prob = clf.predict_proba(XU)[:,1]\n",
    "        prob = clf.predict_proba(XU)\n",
    "        prob2 = 2*prob[:,1]-1\n",
    "        grad_U = np.multiply(grad1, prob2[:,None]) # expected grad\n",
    "        # print(grad_U.shape)\n",
    "        cossim = np.matmul(grad_U, grad_w)\n",
    "        # cossim = np.abs(cossim)\n",
    "        # print(cossim.shape)\n",
    "        ent = -prob[:,0]*np.log(prob[:,0])-prob[:,1]*np.log(prob[:,1])\n",
    "        score = alpha*ent+(1-alpha)*cossim\n",
    "        \n",
    "        # selection\n",
    "        arg = np.argpartition(score, -B)\n",
    "        lind = arg[-B:]\n",
    "        uind = arg[:-B]\n",
    "        XL = np.vstack([XL, XU[lind,:]])\n",
    "        yL = np.append(yL, yU[lind])\n",
    "        zL = np.append(zL, yU[lind])\n",
    "        XU = XU[uind,:]\n",
    "        yU = yU[uind]\n",
    "        zU = zU[uind]\n",
    "        XL0 = XL[zL==0]\n",
    "        XL1 = XL[zL==1]\n",
    "        yL0 = yL[zL==0]\n",
    "        yL1 = yL[zL==1]\n",
    "        XU0 = XU[zU==0]\n",
    "        XU1 = XU[zU==1]\n",
    "        yU0 = yU[zU==0]\n",
    "        yU1 = yU[zU==1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75566667 0.77188889 0.77666667 0.78311111 0.78722222 0.79333333\n",
      " 0.79711111 0.79822222 0.80088889 0.80433333 0.80977778 0.811\n",
      " 0.81211111 0.815      0.81777778 0.81766667 0.82044444 0.82388889\n",
      " 0.82755556 0.82833333 0.82788889 0.83044444 0.83377778 0.83522222\n",
      " 0.83733333 0.83844444 0.841      0.84277778 0.84422222 0.84333333\n",
      " 0.84544444 0.84377778 0.84722222 0.85066667 0.85111111 0.85088889\n",
      " 0.85244444 0.85422222 0.85533333 0.85511111 0.85666667 0.85988889\n",
      " 0.86011111 0.86111111 0.86133333 0.86155556 0.86266667 0.86333333\n",
      " 0.86444444 0.86455556]\n",
      "[0.77135783 0.78625913 0.78995791 0.80091396 0.80380853 0.81204705\n",
      " 0.816678   0.81742605 0.81894531 0.82078539 0.82739963 0.82793713\n",
      " 0.82880853 0.83147865 0.83730385 0.83941355 0.84167957 0.84476994\n",
      " 0.84823258 0.85085097 0.84884439 0.85134927 0.85751015 0.85945953\n",
      " 0.86247282 0.86349438 0.86666745 0.8684289  0.86950505 0.86776332\n",
      " 0.87097993 0.86976889 0.87211527 0.87685391 0.87639932 0.87591346\n",
      " 0.8779547  0.87880776 0.88066713 0.88115443 0.88179753 0.8868683\n",
      " 0.88482143 0.88718011 0.88703637 0.88801911 0.88834979 0.88946269\n",
      " 0.89045019 0.89110156]\n",
      "[0.72355469 0.7430607  0.75007008 0.74751295 0.75433992 0.75634092\n",
      " 0.75814202 0.76017779 0.7655285  0.77202673 0.77506287 0.77766333\n",
      " 0.77933076 0.7830889  0.77983823 0.77499274 0.7787725  0.78278321\n",
      " 0.78694803 0.78409241 0.78654819 0.78923107 0.78694093 0.78729968\n",
      " 0.78749212 0.78884334 0.79026965 0.79219137 0.79460005 0.79548279\n",
      " 0.79535478 0.79258989 0.79829836 0.79905625 0.80126477 0.80175683\n",
      " 0.8024514  0.80611359 0.80570922 0.80411506 0.8073455  0.80706327\n",
      " 0.81174494 0.81010557 0.81101472 0.80966674 0.81235648 0.81219722\n",
      " 0.81349862 0.81255566]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_te, axis=0))\n",
    "print(np.mean(acc_te0, axis=0))\n",
    "print(np.mean(acc_te1, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'acc_te':acc_te, 'acc_te0':acc_te0, 'acc_te1':acc_te1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('fairAL_alpha_agg.res','wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4]\n",
      " [10 12]\n",
      " [21 24]]\n",
      "[1 3 5]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[3,4],[5,6],[7,8]])\n",
    "b=np.array([1,2,3])\n",
    "c=np.multiply(a,b[:,None])\n",
    "print(c)\n",
    "d= 2*b-1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
